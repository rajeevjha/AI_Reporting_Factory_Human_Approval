{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de4f56d9-4038-482f-b1a0-fba34b4df702",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Databricks notebook source \n",
    "Publish Approved Views (Spark-based)# This notebook:\n",
    "1. Reads the candidate queries table for `status='approved'`\n",
    "2. Creates or replaces the corresponding UC views using Spark SQL\n",
    "3. Updates the status to `published`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46db0b77-d69f-46e4-b851-e7ab8d39b047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "CATALOG='finance'\n",
    "SCHEMA='kyc_gold'\n",
    "CAND = f'{CATALOG}.{SCHEMA}.ai_sql_candidates'\n",
    "REPORT_CAND = f'{CATALOG}.{SCHEMA}.report_candidates'\n",
    "\n",
    "# 1) Ensure report_candidates exists\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {REPORT_CAND} (\n",
    "  id STRING,\n",
    "  report_name STRING,\n",
    "  dataset_view STRING,\n",
    "  chart_type STRING,\n",
    "  filters STRING,\n",
    "  owner STRING,\n",
    "  status STRING,            -- PENDING, APPROVED, REJECTED, PUBLISHED\n",
    "  dashboard_id STRING,\n",
    "  report_url STRING,\n",
    "  submitted_at TIMESTAMP,\n",
    "  decision_at TIMESTAMP,\n",
    "  published_at TIMESTAMP\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# 2) Fetch APPROVED AI SQL\n",
    "rows = spark.sql(f\"SELECT id, report_name, generated_sql FROM {CAND} WHERE status ='APPROVED'\").collect()\n",
    "print(f\"Approved items: {len(rows)}\")\n",
    "\n",
    "# 3) For each, create/replace the view, grant, mark PUBLISHED, and seed a report candidate (if not already present)\n",
    "current_user = spark.sql(\"SELECT current_user() AS u\").collect()[0][\"u\"]\n",
    "\n",
    "for r in rows:\n",
    "    view_name = r[\"report_name\"]\n",
    "    sql_text = r[\"generated_sql\"]\n",
    "\n",
    "    # Create/replace the view\n",
    "    spark.sql(f\"CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.{view_name} AS {sql_text}\")\n",
    "    spark.sql(f\"ALTER VIEW {CATALOG}.{SCHEMA}.{view_name} SET TBLPROPERTIES ('rf.generated'='true')\")\n",
    "    #spark.sql(f\"GRANT SELECT ON VIEW {CATALOG}.{SCHEMA}.{view_name} TO `{GRANT_GROUP}`\")\n",
    "    spark.sql(f\"UPDATE {CAND} SET status='PUBLISHED', published_at=current_timestamp() WHERE id='{r['id']}'\")\n",
    "    print(f\"Published view: {view_name}\")\n",
    "\n",
    "    # ---- Heuristics to propose a default report row ----\n",
    "    # Infer a chart type: if there is >=1 numeric and >=1 non-numeric column -> bar; else table\n",
    "    df = spark.table(f\"{CATALOG}.{SCHEMA}.{view_name}\")\n",
    "    dtypes = dict(df.dtypes)\n",
    "    num_cols = [c for c,t in dtypes.items() if t.lower() not in ('string','date','timestamp')]\n",
    "    cat_cols = [c for c,t in dtypes.items() if t.lower() in ('string','date','timestamp')]\n",
    "    default_chart = \"bar\" if (num_cols and cat_cols) else \"table\"\n",
    "\n",
    "    # Derive a simple report name from view name\n",
    "    report_name = view_name\n",
    "\n",
    "    # Avoid duplicates: only insert if no PENDING/APPROVED/PUBLISHED row exists for this dataset_view\n",
    "    existing = spark.sql(f\"\"\"\n",
    "      SELECT COUNT(*) AS c FROM {REPORT_CAND}\n",
    "      WHERE dataset_view = '{view_name}'\n",
    "        AND status IN ('PENDING','APPROVED','PUBLISHED')\n",
    "    \"\"\").collect()[0][\"c\"]\n",
    "\n",
    "    if existing == 0:\n",
    "        # Use Spark SQL uuid() for the id\n",
    "        spark.sql(f\"\"\"\n",
    "          INSERT INTO {REPORT_CAND}\n",
    "          SELECT\n",
    "             uuid() AS id,\n",
    "             '{report_name}' AS report_name,\n",
    "             '{view_name}' AS dataset_view,\n",
    "             '{default_chart}' AS chart_type,\n",
    "             '' AS filters,\n",
    "             '{current_user}' AS owner,\n",
    "             'PENDING' AS status,\n",
    "             '' AS dashboard_id,\n",
    "             '' AS report_url,\n",
    "             current_timestamp() AS submitted_at,\n",
    "             NULL AS decision_at,\n",
    "             NULL AS published_at\n",
    "        \"\"\")\n",
    "        print(f\"Seeded report candidate for view: {view_name} (chart={default_chart})\")\n",
    "    else:\n",
    "        print(f\"Report candidate already exists for view: {view_name}\")\n",
    "\n",
    "print(\"Publish + report candidate seeding complete.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_publish_approved_views",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
